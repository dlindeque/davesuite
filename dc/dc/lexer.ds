
import "model.ds";

namespace dc
{
    pattern identifier  = '[a-zA-Z_][a-zA-Z_0-9]*';
    pattern stringre    = '"(([^"\\]|\e)|(\\(.|\e)))*"';
    pattern hex         = '[a-fA-F0-9]';
    pattern int         = '0|([1-9][0-9]*)';
    pattern charclass   = '[saAde]';

    automata comment // ../*
    {
        '\*+[/]' return -> token TokenType.Comment;
        '\*+[^/]'       -> token TokenType.Comment;
        '\*+\e'         -> token TokenType.Error;
        '[^\*]+'        -> token TokenType.Comment;
        '\e'            -> token TokenType.Error;
    };

    set rechar
    {
        '\\x{hex}{4}'   -> value TokenType.Char;
        '\\x{hex}{0,3}' -> value TokenType.Error;
        '\\{charclass}' -> value TokenType.CharClass;
        '\.'            -> value TokenType.CharClass;
        '[^\\]'         -> value TokenType.Char;
        '\\.'           -> value TokenType.Char;
    };

    automata rebrace // ..{
    {
        '\}' return     -> token TokenType.CloseBrace;
        '{identifier}'  -> value TokenType.Identifier;
        '\.'            -> token TokenType.Dot;
        '{int}'         -> value TokenType.Number;
        ','             -> token TokenType.Comma;
        '\e'            -> token TokenType.Error;
        '.'             -> token TokenType.Error;
    };

    automata resqr // ..[
    {
        ']' return      -> token TokenType.CloseSquare;
        '^'             -> token TokenType.Hat;
        '-'             -> token TokenType.Hyphen;

        include rechar;

        '.'             -> token TokenType.Error;
        '\e'            -> token TokenType.Error;
    };

    automata re // ..'
    {
        '\'' return         -> token TokenType.ReEnd;

        '\('                -> token TokenType.OpenParenthesis;
        '\)'                -> token TokenType.CloseParenthesis;
        '\{' goto rebrace   -> token TokenType.OpenBrace;
        '\[' goto resqr     -> token TokenType.OpenSquare;
        '\*'                -> token TokenType.Asterisk;
        '\?'                -> token TokenType.Question;
        '\+'                -> token TokenType.Plus;
        '\|'                -> token TokenType.Pipe;

        include rechar;

        '.'                 -> token TokenType.Error;
        '\e'                -> token TokenType.Error;
    };

    automata lexer
    {
        '\s+'                           -> token TokenType.Whitespace;

        'import'                        -> keyword TokenType.Import;
        'set'                           -> keyword TokenType.Set;
        'start'                         -> keyword TokenType.Start;
        'namespace'                     -> keyword TokenType.Namespace;
        'pattern'                       -> keyword TokenType.Pattern;
        'automata'                      -> keyword TokenType.Automata;
        'include'                       -> keyword TokenType.Include;
        'alias'                         -> keyword TokenType.Alias;
        'goto'                          -> keyword TokenType.Goto;
        'return'                        -> keyword TokenType.Return;
        'enum'                          -> keyword TokenType.Enum;
        'production'                    -> keyword TokenType.Production;
        'type'                          -> keyword TokenType.Type;
        'abstract'                      -> keyword TokenType.Abstract;
        'sealed'                        -> keyword TokenType.Sealed;
        'word'                          -> keyword TokenType.Word;
        'dword'                         -> keyword TokenType.DWord;
        'int8'                          -> keyword TokenType.Int8;
        'int16'                         -> keyword TokenType.Int16;
        'int32'                         -> keyword TokenType.Int32;
        'int64'                         -> keyword TokenType.Int64;
        'string'                        -> keyword TokenType.StringKeyword;
        'wstring'                       -> keyword TokenType.WString;
        'float'                         -> keyword TokenType.FloatKeyword;
        'dfloat'                        -> keyword TokenType.DFloat;

        '='                             -> token TokenType.Equals;
        '\.'                            -> token TokenType.Dot;
        ';'                             -> token TokenType.Semicolon;
        '\{'                            -> token TokenType.OpenBrace;
        '\}'                            -> token TokenType.CloseBrace;
        '->'                            -> token TokenType.ProducedBy;
        ','                             -> token TokenType.Comma;
        '\['                            -> token TokenType.OpenSquare;
        '\]'                            -> token TokenType.CloseSquare;
        ':'                             -> token TokenType.Colon;
        '<'                             -> token TokenType.OpenTriangle;
        '>'                             -> token TokenType.CloseTriangle;

        '\'' goto re                    -> token TokenType.ReStart;
        '/\*' goto comment              -> token TokenType.Comment;

        '//(\n|\e)'                     -> token TokenType.Comment;
        '//[^/\n\e][^\n\e]*(\n|\e)'     -> token TokenType.Comment;
        '////[^\n\e]*(\n|\e)'           -> token TokenType.Comment;
        '///(\n|\e)'                    -> value TokenType.Documentation;
        '///[^/\n\e][^\n\e]*(\n|\e)'    -> value TokenType.Documentation;

        '{stringre}'                    -> value TokenType.String;
        '{identifier}'                  -> value TokenType.Identifier;
        '.'                             -> token TokenType.Error;
        '\e'                            -> token TokenType.EOD;
    };
};

set start = dc.lexer;